{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pca Bankcruptcy.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["3kRHfQ9A5w1a"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HZWsWCYpe5BG"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd /content/drive/My Drive/newdata"],"metadata":{"id":"ja8sRxQ_fA9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data imputation\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE\n","import pandas as pd\n","import sys\n","import seaborn as sns\n","import scipy as sp\n","import numpy as np\n","import shelve\n","from sklearn import preprocessing\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","# ANN\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation,Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# model evaluation\n","from sklearn.metrics import confusion_matrix, classification_report, f1_score\n","from sklearn.metrics import plot_confusion_matrix\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"],"metadata":{"id":"u6r82jvjfJ8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/MyDrive/newdata/train_bankcruptcy.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/newdata/test_bankcruptcy.csv')"],"metadata":{"id":"ljHHVt39fM-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"id":"F6jzdbnxfrDQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_cat_var(df):\n","\n","    cat_colnames = list(df.select_dtypes('object').columns)\n","\n","    for col in cat_colnames:\n","      print('Categorical column: {}\\n'.format(col))\n","      print('Number of unique entries: {}\\n'.format(df[col].nunique()))\n","      print('Unique entry names:\\n{}\\n'.format(df[col].unique()))\n","      print('Value counts of each entry:\\n{}\\n'.format(df[col].value_counts(dropna=False)))\n","      print('---------------------------------------------------------')\n","\n","    return"],"metadata":{"id":"9V8vVQ-uftIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# modules"],"metadata":{"id":"3kRHfQ9A5w1a"}},{"cell_type":"code","source":["def plot_kde_hist_var(df,varList,calcStat = True, drawAll = False):\n","    numVar = len(varList)\n","\n","    plt.figure(figsize=(10,numVar*4))\n","    ks_stat_list = []\n","    ks_pval_list = []\n","    try:\n","        for i,var in enumerate(varList):\n","            tgt_true = df.loc[df['TARGET']==1,var]\n","            tgt_false = df.loc[df['TARGET']==0,var]\n","\n","            # calculate statistical significance between both populations\n","            if calcStat == True:\n","                (ks_stat,ks_pval)= sp.stats.ks_2samp(tgt_true,tgt_false)\n","                ks_stat_list.append(ks_stat)\n","                ks_pval_list.append(ks_pval)\n","                ks_hval_list = [True for hyp in ks_pval_list if hyp<0.05]\n","\n","            #\n","            median_tgt_true = tgt_true.median()\n","            median_tgt_false = tgt_false.median()\n","            corrVal = df['TARGET'].corr(df[var])\n","            print('Median Value of {} when Target (True): {:.6f}'.format(var,median_tgt_true))\n","            print('Median Value of {} when Target (False): {:.6f}'.format(var,median_tgt_false))\n","            print('Pearson Correlation of {} with Target (True): {:.6f}'.format(var,corrVal))\n","\n","            # drawing KDE distributions\n","            tgt_true.dropna(inplace=True) # require to dropna for sns.distplot function\n","            tgt_false.dropna(inplace=True)\n","            plt.subplot(numVar,1,i+1)\n","            sns.distplot(tgt_true,rug=drawAll,kde=drawAll,label='Target: True')\n","            sns.distplot(tgt_false,rug=drawAll,kde=drawAll,label='Target: False')\n","            plt.legend()\n","            #plt.title(var)\n","    except TypeError as error:\n","        print(error)\n","        print('Features are objects.  Need ints/floats')\n","\n","    return ks_hval_list, ks_pval_list\n","def label_encoding_df(df,cat_limit = 2):\n","\n","    le = preprocessing.LabelEncoder()\n","    le_count = 0\n","    label_encode_list = []\n","    for col in df:\n","        if df[col].dtype=='object':\n","            if df[col].nunique(dropna=False) <= cat_limit:\n","                print(col)\n","                le_count += 1\n","                le.fit(df[col])\n","                df[col] = le.transform(df[col])\n","                label_encode_list.append(col)\n","\n","    print('{0} columns were label encoded'.format(le_count))\n","\n","    return df, label_encode_list\n","def print_tab_miss_val(df,miss_val_thresh=50,numColPrint=10,printData=False):\n","    # Evaluate missing values in the data\n","    num_miss_val = df.isnull().sum()\n","    pct_miss_val = num_miss_val/df.shape[0]*100\n","\n","    tab_miss_val = pd.concat([num_miss_val,pct_miss_val],axis=1)\n","    tab_miss_val.columns = ['Missing Values','Percentage']\n","    tab_miss_val  = tab_miss_val[tab_miss_val['Missing Values']>0]\n","    tab_miss_val['Percentage'] = tab_miss_val['Percentage'].round(1)\n","    tab_miss_val.sort_values(['Percentage'],ascending=False,inplace=True)\n","\n","    numCol_miss_val = tab_miss_val.shape[0]\n","    numCol_total = df.shape[1]\n","    pctCol_miss_val = round((numCol_miss_val/numCol_total)*100)\n","\n","    numCol_crit_miss_val = tab_miss_val[tab_miss_val['Percentage'] > miss_val_thresh].shape[0]\n","    pctCol_crit_miss_val = round(numCol_crit_miss_val/numCol_total*100)\n","\n","    info_miss_val = pd.Series(data=[numCol_miss_val,pctCol_miss_val,numCol_crit_miss_val,pctCol_crit_miss_val],\n","              index=['Cols Missing Values','Cols Missing Values (%)',\n","            'Cols Critical Missing Values', 'Cols Critical Missing Values (%)'])\n","\n","    if printData==True:\n","        print(info_miss_val)\n","        print('\\n Top {} columns with missing values is as follows:'.format(numColPrint))\n","        print(tab_miss_val['Percentage'].head(numColPrint))\n","\n","    return info_miss_val, tab_miss_val\n","def convSeries2Str(seriesData):\n","    strList = ''\n","    for idx,val in seriesData.iteritems():\n","        strVal = '{}({}), '.format(idx,val)\n","        strList = strList + strVal\n","\n","    return strList\n","def print_basic_info_df(df,bal_thresh=30):\n","\n","    (numRow,numCol) = df.shape\n","    memory = int(sys.getsizeof(df)/(10**6))\n","\n","    dtypeVals = df.dtypes.value_counts()\n","    dtypeStr = convSeries2Str(dtypeVals)\n","\n","    # Extract the unique variables of each  column that are strings, and extract the unique variables including NaNs\n","    catVals = df.select_dtypes('object').nunique(dropna=False)\n","    catStr = convSeries2Str(catVals)\n","\n","    # Is the dataframe balanced?\n","    if 'TARGET' in df:\n","        (numRow,numCol) = df.shape\n","        pctTarget_true = int(df['TARGET'].sum()/numRow*100)\n","        if pctTarget_true > 100-bal_thresh or pctTarget_true < bal_thresh:\n","            isBalanced='No'\n","        else:\n","            isBalanced='True'\n","    else:\n","        isBalanced='N/A'\n","        pctTarget_true='N/A'\n","\n","    series_data = [numRow, numCol, dtypeStr,memory,pctTarget_true,isBalanced,catStr]\n","    series_idx = ['Num rows','Num cols','Dtype','Memory (MB)','True (%)','Is Balanced','Categorical cols']\n","    series_info = pd.Series(series_data,index = series_idx)\n","\n","    dict_info = [{'Num rows': numRow, 'Num cols': numCol,'Dtype': dtypeStr,\n","    'Memory (MB)': memory,'True (%)': pctTarget_true,'Is Balanced':isBalanced,\n","    'Category cols': catStr} ]\n","\n","    return series_info\n","def print_compare_df(df1,df2,miss_val_thresh=50,bal_thresh=30,printCompareData=False):\n","\n","    # Prints combined basic data of each dataframe\n","    df1_basicinfo = print_basic_info_df(df1)\n","    df2_basicinfo = print_basic_info_df(df2)\n","    comb_basic_info = pd.concat([df1_basicinfo,df2_basicinfo],axis=1)\n","\n","    # Compare missing value data\n","    miss_val_info_df1, miss_val_tab_df1 =  print_tab_miss_val(df1)\n","    miss_val_info_df2, miss_val_tab_df2 =  print_tab_miss_val(df2)\n","    comb_miss_val_info = pd.concat([miss_val_info_df1,miss_val_info_df2],axis=1)\n","\n","\n","    s1 = set(df1.dtypes)\n","    s2 = set(df2.dtypes)\n","\n","    # Compare two dataframes for number of missing categories, and values in each category\n","    # As the training and test datasets are of different sizes, the training dataset may have values\n","    # in the feature columns that are not in the test datasets.\n","    # This code analyzes whether there are more than 5 different unique variables between feature columns\n","    # of the test and training datasets.\n","    if s1 == s2:\n","        for x in list(s1):\n","\n","            df1_catCols = df1.select_dtypes(x).nunique(dropna=False)\n","            df2_catCols = df2.select_dtypes(x).nunique(dropna=False)\n","            diff_catColsList = df1_catCols - df2_catCols\n","            diff_catCols = diff_catColsList[(diff_catColsList<5) & (diff_catColsList>-5) & (diff_catColsList!=0)]\n","            for y in diff_catCols.index:\n","                df1_valCnt = df1[y].value_counts()\n","                df1_valCnt.name = df1_valCnt.name+'_DF1'\n","                df2_valCnt = df2[y].value_counts()\n","                df2_valCnt.name = df2_valCnt.name+'_DF2'\n","                comb_valCnt = pd.concat([df1_valCnt,df2_valCnt],axis=1)\n","\n","                if printCompareData==True:\n","                    print(comb_valCnt)\n","                    plt.figure()\n","                    comb_valCnt.plot.bar(rot=60,title=y)\n","\n","\n","\n","    return comb_basic_info, comb_miss_val_info, miss_val_tab_df1, miss_val_tab_df2"],"metadata":{"id":"GM04AC7W0_HQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocess"],"metadata":{"id":"gBE-gcRr54PN"}},{"cell_type":"code","source":["df_train = df_train.replace({'?':np.nan})\n","df_test = df_test.replace({'?':np.nan})\n","df_train = df_train.rename(columns={\"class\":\"TARGET\"})"],"metadata":{"id":"0mmBZ0uggkHv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in df_train.columns:\n","  df_train[i] = pd.to_numeric(df_train[i])\n","  "],"metadata":{"id":"CKig-uRt7GgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extract_cat_var(df_train)"],"metadata":{"id":"aLtK8J1Q6Qjg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comb_basic_info,comb_miss_val,comb_miss_val_app_train,comb_miss_val_app_test = print_compare_df(df_train,df_test)\n","\n","print('\\nCombined basic info:\\n{}'.format(comb_basic_info))\n","print('\\nCombined missing info:\\n{}'.format(comb_miss_val))"],"metadata":{"id":"Rw0p4SW21DPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_compare_df(df_train,df_test,printCompareData=False)"],"metadata":{"id":"ylmcL_oSp_dO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train['total_liabilities_minus_cash_over_sales'].describe()"],"metadata":{"id":"-YgrQX8YNXql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train_corr = df_train.corr()\n","df_app_train_corr_target = df_train_corr['TARGET'].sort_values()\n","print('+ve corr: \\n{0}'.format(df_app_train_corr_target.tail(32)))\n","print('-ve corr: \\n{0}'.format(df_app_train_corr_target.head(32)))"],"metadata":{"id":"ZH1Sjhrq9YjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["var_pos_corr_list = df_app_train_corr_target.head(10).index.values\n","var_neg_corr_list = df_app_train_corr_target[-2:-10:-1].index.values\n","\n","print(var_pos_corr_list)\n","print(var_neg_corr_list)\n","\n","#plot_kde_hist_var(df_train,var_pos_corr_list,drawAll=True)\n","plot_kde_hist_var(df_train,var_neg_corr_list,drawAll=True)"],"metadata":{"id":"z_nAHvLb9nk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["condi1 = df_train['total_liabilities_over_total_assets'] <1\n","condi2 = df_train['total_liabilities_over_total_assets'] > 0\n","condi3 = df_train['total_liabilities_over_total_assets'] = 1\n","df_train = df_train[(condi1|condi3)&condi2]"],"metadata":{"id":"3BjF2XOgKzEu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corr_df = df_train.corr()\n","high_corr = ~(corr_df.mask(np.eye(len(corr_df ), dtype=bool)).abs() > 0.5).any()\n","high_corr\n","\n","corr_df = corr_df.loc[high_corr,high_corr]\n","print(corr_df.columns)"],"metadata":{"id":"r7SxC7WnelXo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#['TARGET','logarithm_of_total_assets','working_capital_over_total_assets','retained_earnings_over_total_assets','profit_on_sales_over_sales']"],"metadata":{"id":"n6mw-7jzN3-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_ext_src = df_train[list(corr_df.columns)] \n","df_ext_src_corr = df_ext_src.corr()\n","sns.heatmap(df_ext_src_corr,vmin=-1.0,vmax=1.0,annot=True)\n","sns.set(rc={'figure.figsize':(160.7,80.27)})"],"metadata":{"id":"c5g5CDXa9n40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train[['EBIT_over_total_assets', 'gross_profit_plus_interest_over_total_assets']].describe()"],"metadata":{"id":"YAeoAzWuSVFN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_ext_src_sample = df_ext_src[['total_liabilities_over_total_assets','TARGET']].dropna().sample(5000)\n","grid = sns.PairGrid(data = df_ext_src_sample, diag_sharey=True,\n","                    hue = 'TARGET', \n","                    vars = [x for x in list(df_ext_src_sample.columns) if x != 'TARGET'])\n","\n","grid.map_upper(plt.scatter, alpha = 0.2)\n","grid.map_diag(sns.kdeplot)\n","grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);"],"metadata":{"id":"nMzCLWbc__lJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["var_list = ['total_liabilities_over_total_assets']"],"metadata":{"id":"EqyJ4M4zAOpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.drop(columns=['total_assets_over_total_liabilities'],inplace=True)"],"metadata":{"id":"7o7UjKGbOFWE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train['sales_over_fixed_assets'].describe()"],"metadata":{"id":"TVjDQTgk9oKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train['net_profit_over_total_assets'].hist()"],"metadata":{"id":"CqHRy8JCQL8S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train['total_liabilities_over_total_assets'].hist()"],"metadata":{"id":"wiwC5OCwej3p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dealing missing value by KNN imputation"],"metadata":{"id":"iNzR_BxmbaX1"}},{"cell_type":"code","source":["import sklearn.neighbors._base\n","import sys\n","sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=6)"],"metadata":{"id":"-PYf0sgtMjj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"id":"d89z2UkFmsY_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.shape"],"metadata":{"id":"6FSwrYJHle-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df_train\n","X_new = imputer.fit_transform(X)\n","\n","col = list(df_train.columns)\n","df_train_full = pd.DataFrame(X_new, columns= col)\n","train = df_train_full.copy()"],"metadata":{"id":"AUyV849RcoWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = train.drop(columns='TARGET')\n","y = train.TARGET\n","X_train, X_test,y_train,y_test = train_test_split(X, y,stratify=y)\n"],"metadata":{"id":"t6IhZxBmsOg7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class imbalance is treated\n","sns.set_style('white');\n","sns.set_context(context='notebook',font_scale=1.2)\n","sns.countplot(x=y_train);\n","plt.title('Target variable balanced');"],"metadata":{"id":"RrXdAgajwvDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import RobustScaler\n","scaler = RobustScaler()\n","scaler.fit(X_train)\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)\n"],"metadata":{"id":"h1VJozMYkPUJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PCA\n"],"metadata":{"id":"deLFCQq4pw5U"}},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","pca = PCA(n_components=33)\n","X_train = pca.fit_transform(X_train)\n","X_test = pca.fit_transform(X_test)"],"metadata":{"id":"BJrgvDfjpwia"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ANN model"],"metadata":{"id":"TDh3ecC8rIDn"}},{"cell_type":"code","source":["# early stopping\n","early_stop =  EarlyStopping(monitor='val_auc',mode='max', verbose=1, patience=27,restore_best_weights=True)\n","\n","# ANN\n","model =  Sequential()\n","\n","model.add(Dense(units=8,activation='relu'))\n","model.add(Dropout(0.10))\n","\n","model.add(Dense(units=4,activation='relu'))\n","\n","model.add(Dense(units=1,activation='sigmoid'))\n","\n","# compile ANN\n","model.compile(loss='binary_crossentropy', optimizer='adam',metrics = ['accuracy'])"],"metadata":{"id":"uiVrirhbtjtl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train ANN\n","model.fit(x=X_train, \n","          y=y_train, \n","          epochs=120,\n","          validation_data=(X_test, y_test), verbose=1,\n","          callbacks=[early_stop]\n","          )"],"metadata":{"id":"tsDg3gSttnFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model history to df\n","loss_plot = pd.DataFrame(model.history.history)\n","accuracy_plot = pd.DataFrame(model.history.history)\n","\n","#  accuracy and loss plot\n","fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(14,4))\n","plt.style.use('seaborn')\n","ax1.plot(loss_plot.loc[:, ['loss']], label='Training loss');\n","ax1.plot(loss_plot.loc[:, ['val_loss']],label='Validation loss');\n","ax1.set_title('Training and Validation loss')\n","ax1.set_xlabel('epochs')\n","ax1.set_ylabel('Loss')\n","ax1.legend(loc=\"best\");\n","\n","ax2.plot(accuracy_plot.loc[:, ['accuracy']],label='Training_accuracy');\n","ax2.plot(accuracy_plot.loc[:, ['val_accuracy']], label='Validation_accuracy');\n","ax2.set_title('Training_and_Validation_accuracy');\n","ax2.set_xlabel('epochs')\n","ax2.set_ylabel('accuracy')\n","ax2.legend(loc=\"best\");"],"metadata":{"id":"GFHsnZ6nugqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(X_test)\n","y_pred = (y_pred > 0.1)"],"metadata":{"id":"_0Gx8JE3uo9I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred))\n"],"metadata":{"id":"1H9r25tmulVq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.heatmap(confusion_matrix(y_test,y_pred,normalize='true'), annot=True);#\n"],"metadata":{"id":"8sj6lF7duvZM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# XGB model\n"],"metadata":{"id":"k-CWb35Oyuis"}},{"cell_type":"code","source":["from xgboost import XGBClassifier\n","import xgboost as xgb"],"metadata":{"id":"gQjzpu22yznD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf = XGBClassifier(objective='binary:logistic',seed=42,scale_pos_weight=2.2775)"],"metadata":{"id":"9Q4Np0Bmy7WQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric='aucpr', eval_set=[[X_test,y_test]])"],"metadata":{"id":"JKh_LhLVy9KX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred1 = clf.predict(X_test)"],"metadata":{"id":"4mTFzpd6zHuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred1))\n"],"metadata":{"id":"6qqACkaIzO7Q"},"execution_count":null,"outputs":[]}]}